# Hashmancer GPU-Enabled Docker Image
# Optimized for NVIDIA GPU acceleration with CUDA support

FROM nvidia/cuda:11.8-devel-ubuntu22.04 as builder

# Prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 \
    python3-pip \
    python3-dev \
    python3-venv \
    build-essential \
    gcc \
    g++ \
    cmake \
    pkg-config \
    libffi-dev \
    libssl-dev \
    git \
    curl \
    wget \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Create symlink for python
RUN ln -s /usr/bin/python3 /usr/bin/python

# Create virtual environment
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Upgrade pip and install build tools
RUN pip install --no-cache-dir --upgrade pip setuptools wheel

# Copy requirements and install Python dependencies
COPY hashmancer/server/requirements*.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# Install PyTorch with CUDA support
RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install additional GPU-accelerated packages
RUN pip install --no-cache-dir \
    cupy-cuda11x \
    numba \
    nvidia-ml-py3

# Production stage
FROM nvidia/cuda:11.8-runtime-ubuntu22.04

# Prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Install runtime dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 \
    python3-distutils \
    curl \
    htop \
    nvtop \
    procps \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create symlink for python
RUN ln -s /usr/bin/python3 /usr/bin/python

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Set CUDA environment variables
ENV CUDA_VISIBLE_DEVICES=all
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
ENV CUDA_HOME=/usr/local/cuda
ENV PATH="${CUDA_HOME}/bin:${PATH}"
ENV LD_LIBRARY_PATH="${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"

# Create non-root user
RUN groupadd -r hashmancer && useradd -r -g hashmancer -d /app -s /bin/bash hashmancer

# Create directories
RUN mkdir -p /app/{data,logs,config,temp,gpu_cache} && \
    chown -R hashmancer:hashmancer /app

WORKDIR /app

# Copy application code
COPY --chown=hashmancer:hashmancer . /app/

# Switch to non-root user
USER hashmancer

# Set Python path and environment
ENV PYTHONPATH="/app:$PYTHONPATH"
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV CUDA_CACHE_PATH="/app/gpu_cache"
ENV NUMBA_CACHE_DIR="/app/gpu_cache/numba"

# GPU-specific environment variables
ENV TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6+PTX"
ENV FORCE_CUDA=1

# Health check with GPU awareness
HEALTHCHECK --interval=30s --timeout=15s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health && python -c "import torch; assert torch.cuda.is_available()" || exit 1

EXPOSE 8000

WORKDIR /app/hashmancer/server

# Use exec form for proper signal handling
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]