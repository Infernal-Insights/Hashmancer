version: '3.8'

services:
  # Redis Service - High Performance Configuration
  redis:
    image: redis:7-alpine
    container_name: hashmancer-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    ports:
      - "6379:6379"
    networks:
      - hashmancer-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 1G

  # Hashmancer Server
  server:
    build:
      context: .
      dockerfile: docker/server/Dockerfile
      args:
        - BUILD_ENV=production
    container_name: hashmancer-server
    restart: unless-stopped
    ports:
      - "8080:8080"
      - "8000:8000"  # API port
    environment:
      # Redis Configuration
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_MAX_CONNECTIONS=50
      - REDIS_CONNECTION_TIMEOUT=10
      
      # Server Configuration
      - HASHMANCER_HOST=0.0.0.0
      - HASHMANCER_PORT=8080
      - API_PORT=8000
      - LOG_LEVEL=INFO
      
      # Performance Settings
      - WORKERS=4
      - MAX_REQUESTS=1000
      - MAX_REQUESTS_JITTER=50
      
      # Security
      - SECURE_SESSION=true
      - SESSION_TIMEOUT=3600
      
    volumes:
      - server_data:/app/data
      - ./logs:/app/logs
      - ./config:/app/config:ro
      - ./wordlists:/app/wordlists:ro
    networks:
      - hashmancer-network
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'

  # GPU Worker with Hashcat and Darkling
  worker-gpu:
    build:
      context: .
      dockerfile: docker/worker/Dockerfile.gpu
      args:
        - CUDA_VERSION=12.1
        - HASHCAT_VERSION=6.2.6
    container_name: hashmancer-worker-gpu
    restart: unless-stopped
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # Redis Configuration
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      
      # Worker Configuration  
      - SERVER_HOST=server
      - SERVER_PORT=8080
      - WORKER_ID=gpu-worker-1
      - WORKER_TYPE=gpu
      - LOG_LEVEL=INFO
      
      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=all
      - GPU_MEMORY_LIMIT=0.9  # Use 90% of GPU memory
      
      # Engine Configuration
      - HASHCAT_BINARY=/usr/local/bin/hashcat
      - DARKLING_ENABLED=true
      - HASHCAT_ENABLED=true
      - DEFAULT_ENGINE=darkling
      
    volumes:
      - worker_data:/app/data
      - ./logs:/app/logs
      - /tmp:/tmp:rw  # Temporary file access
    networks:
      - hashmancer-network
    depends_on:
      - server
      - redis
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # CPU-Only Worker (for systems without GPU)
  worker-cpu:
    build:
      context: .
      dockerfile: docker/worker/Dockerfile.cpu
      args:
        - HASHCAT_VERSION=6.2.6
    container_name: hashmancer-worker-cpu
    restart: unless-stopped
    environment:
      # Redis Configuration
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      
      # Worker Configuration
      - SERVER_HOST=server
      - SERVER_PORT=8080
      - WORKER_ID=cpu-worker-1
      - WORKER_TYPE=cpu
      - LOG_LEVEL=INFO
      
      # Engine Configuration
      - HASHCAT_BINARY=/usr/local/bin/hashcat
      - DARKLING_ENABLED=true
      - HASHCAT_ENABLED=true
      - DEFAULT_ENGINE=darkling
      
    volumes:
      - worker_data:/app/data
      - ./logs:/app/logs
    networks:
      - hashmancer-network
    depends_on:
      - server
      - redis
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
        reservations:
          memory: 1G
          cpus: '1'

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: hashmancer-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./ssl:/etc/nginx/ssl:ro
    networks:
      - hashmancer-network
    depends_on:
      - server
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.5'

  # Monitoring Stack (Optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: hashmancer-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - hashmancer-network
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: hashmancer-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=hashmancer123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
    networks:
      - hashmancer-network
    profiles:
      - monitoring

networks:
  hashmancer-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  redis_data:
    driver: local
  server_data:
    driver: local
  worker_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local